{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rjac/miniconda3/envs/restapi/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# %load point.py\n",
    "\"\"\"\n",
    "This module serves as the API provider for point detection.\n",
    "\"\"\"\n",
    "\n",
    "import io\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CABLE_CKPT = 'cables_inference_graph.pb'\n",
    "POLES_CKPT = 'poles_inference_graph.pb'\n",
    "TOPBOTTOM_CKPT = 'top_bottom_inference_graph.pb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph(path_):\n",
    "    detection_graph = tf.Graph()\n",
    "    with detection_graph.as_default():\n",
    "        od_graph_def = tf.GraphDef()\n",
    "        with tf.gfile.GFile(path_, 'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "            tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "    return detection_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "POINT_GRAPH = get_graph(CABLE_CKPT)\n",
    "POLES_GRAPH = get_graph(POLES_CKPT)\n",
    "TOPBOTTOM_GRAPH = get_graph(TOPBOTTOM_CKPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topMiddleBottom(size,middleBoxes):\n",
    "    yt, xt = size\n",
    "    points = OrderedDict({})\n",
    "    \n",
    "    #yi, xi, yh ,xh = topBottomBoxes[0]\n",
    "    #xm = (xi+xh)/2.00\n",
    "    \n",
    "    #pbx = int(xt*xm)\n",
    "    #pbyi = int(yt*yi)\n",
    "    #pbyh = int(yt*yh)\n",
    "    \n",
    "    \n",
    "    #points[\"top\"] = [pbx,pbyi]\n",
    "    \n",
    "    for i,box in enumerate(middleBoxes):\n",
    "        yi, xi, yh ,xh = box\n",
    "        xm = (xi+xh)/2.00\n",
    "        ym = (yi+yh)/2.00\n",
    "    \n",
    "        px = int(xt*xm)\n",
    "        py = int(yt*ym)\n",
    "        \n",
    "        points[\"point{}\".format(i+1)] = [px,py]\n",
    "\n",
    "    #points[\"bottom\"] = [pbx,pbyh]\n",
    "    \n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def namedPoints(size,top,middle,bottom):\n",
    "    yt, xt = size\n",
    "    points = OrderedDict({})\n",
    "    \n",
    "    for i,box in enumerate(top):\n",
    "        yi, xi, yh ,xh = box\n",
    "        xm = (xi+xh)/2.00\n",
    "        ym = (yi+yh)/2.00\n",
    "        px = int(xt*xm)\n",
    "        py = int(yt*ym)\n",
    "        points[\"top{}\".format(i+1)] = [px,py]\n",
    "        \n",
    "    for i,box in enumerate(middle):\n",
    "        yi, xi, yh ,xh = box\n",
    "        xm = (xi+xh)/2.00\n",
    "        ym = (yi+yh)/2.00\n",
    "        px = int(xt*xm)\n",
    "        py = int(yt*ym)\n",
    "        points[\"point{}\".format(i+1)] = [px,py]\n",
    "        \n",
    "    for i,box in enumerate(bottom):\n",
    "        yi, xi, yh ,xh = box\n",
    "        xm = (xi+xh)/2.00\n",
    "        ym = (yi+yh)/2.00\n",
    "        px = int(xt*xm)\n",
    "        py = int(yt*ym)\n",
    "        points[\"bottom{}\".format(i+1)] = [px,py]\n",
    "\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction(image,point_result,pole_result,topbottom_result):\n",
    "    \n",
    "    #poles_boxes = np.average(pole_result['detection_boxes'],weights=pole_result['detection_scores'],axis=0).reshape([1,4])\n",
    "    \n",
    "    objects_boxes = list(point_result['detection_boxes'])\n",
    "    bottom_boxes = [list(topbottom_result['detection_boxes'][i]) for i,x in enumerate(topbottom_result['detection_classes']) if x == 2]\n",
    "    top_boxes = [list(topbottom_result['detection_boxes'][i]) for i,x in enumerate(topbottom_result['detection_classes']) if x == 1]\n",
    "        \n",
    "    result = namedPoints(image.shape[:2],top_boxes,objects_boxes,bottom_boxes)\n",
    "    \n",
    "    return result   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(image, graph):\n",
    "    with graph.as_default():\n",
    "        with tf.Session() as sess:\n",
    "            # Get handles to input and output tensors\n",
    "            ops = tf.get_default_graph().get_operations()\n",
    "            all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "\n",
    "            tensor_dict = {}\n",
    "            for key in ['num_detections', 'detection_boxes', 'detection_scores', 'detection_classes',\n",
    "                        'detection_masks']:\n",
    "                tensor_name = key + ':0'\n",
    "                if tensor_name in all_tensor_names:\n",
    "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(tensor_name)\n",
    "\n",
    "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "            output_dict = sess.run(tensor_dict, feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
    "            \n",
    "            output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "            output_dict['detection_classes'] = output_dict['detection_classes'][0].astype(np.uint8)\n",
    "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "            \n",
    "            output_dict['detection_classes'] = output_dict['detection_classes'][:output_dict['num_detections']] \n",
    "            output_dict['detection_boxes'] = output_dict['detection_boxes'][:output_dict['num_detections']]\n",
    "            output_dict['detection_scores'] = output_dict['detection_scores'][:output_dict['num_detections']]\n",
    "            #print(output_dict)\n",
    "\n",
    "            return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_image(file):\n",
    "    \"\"\"\n",
    "    Given a posted image, classify it using the pretrained model.\n",
    "\n",
    "    This will take 'any size' image, and scale it down to 28x28 like our MNIST\n",
    "    training data -- and convert to grayscale.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file:\n",
    "        Bytestring contents of the uploaded file. This will be in an image file format.\n",
    "    \"\"\"\n",
    "\n",
    "    img_array = np.asarray(bytearray(file.read()), dtype=np.uint8)\n",
    "    img = cv2.imdecode(img_array,cv2.IMREAD_COLOR)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  \n",
    "    image_np = img.copy()\n",
    "\n",
    "    poles_result = run_inference_for_single_image(image_np, POLES_GRAPH)\n",
    "    point_result = run_inference_for_single_image(image_np, POINT_GRAPH)\n",
    "    topbottom_result = run_inference_for_single_image(image_np, TOPBOTTOM_GRAPH)\n",
    "\n",
    "    \n",
    "    result = extraction(img,point_result,poles_result,topbottom_result)\n",
    "\n",
    "    return json.dumps(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (restapi)",
   "language": "python",
   "name": "restapi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
